% ------------------------------------------------------------------------
% Artigo de Exemplo no Formato SBC - Projeto de Big Data (DS340 - UFPR)
% ------------------------------------------------------------------------

\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}

\title{Análise Comparativa de Desempenho entre Databricks e PostgreSQL no Armazenamento e Consulta de Dados Relacionados a Aderência em Cursos Tecnológicos}

\author{Anna Luiza Mariano\inst{1}, Arthur Deretti\inst{1}, Maria Eduarda Ferreira\inst{1} \\ Mateus Xavier\inst{1}, Rafael Pompônio\inst{1}}

\address{Curso de Tecnologia em Análise e Desenvolvimento de Sistemas \\ Universidade Federal do Paraná (UFPR)\\
}

\begin{document}

\maketitle

\begin{resumo}
Este artigo apresenta uma análise comparativa entre a plataforma de processamento de dados Databricks e o sistema relacional PostgreSQL, aplicados ao armazenamento e consulta de dados relacionados a aderência em cursos tecnológicos obtidos a partir do portal público do SISU (Sistema de Seleção Unificada) e do ProUni (Portal Único de Acesso ao Ensino Superior). O objetivo é avaliar o desempenho de cada sistema em operações de leitura, atualização e agregação de dados em um cenário de Big Data.
\end{resumo}

\section{Introdução}

O crescimento acelerado da geração de dados por sensores, redes sociais e dispositivos conectados tornou essencial o uso de tecnologias capazes de armazenar e processar grandes volumes de informações de forma eficiente e distribuída. Nesse cenário, soluções de \textit{Big Data} ganharam destaque por oferecerem escalabilidade e alto desempenho.

Este trabalho compara o Databricks, uma plataforma baseada em processamento distribuído, ao sistema relacional PostgreSQL, aplicando ambos a um conjunto real de dados institucionais. A análise considera tempo de execução, uso de memória e facilidade de modelagem, avaliando em quais contextos cada tecnologia se destaca.

Enquanto o Databricks, apoiado pelo Apache Spark, é projetado para grandes volumes e cenários analíticos complexos, o PostgreSQL mantém sua robustez em aplicações transacionais e estruturadas, com forte ênfase em integridade e consistência. Assim, a comparação evidencia que a escolha entre Big Data e bancos relacionais depende diretamente da natureza do problema, dos requisitos de desempenho e das características dos dados, reforçando que ambas as abordagens podem ser complementares.

\section{Tecnologia Big Data Utilizada}

\subsection{Databricks: Arquitetura e Funcionalidades Técnicas}

O Databricks é uma plataforma unificada para processamento de dados e análise de Big Data, construída sobre o Apache Spark, um dos motores de processamento de dados mais rápidos e eficientes. A plataforma oferece uma solução robusta para o processamento distribuído de grandes volumes de dados, além de integrar recursos avançados de machine learning e inteligência artificial.

\subsubsection{Arquitetura de Nuvem e Processamento Distribuído com Apache Spark}

Databricks foi projetado para rodar nativamente na nuvem, aproveitando as capacidades de escalabilidade, elasticidade e recursos sob demanda oferecidos pelos principais provedores de nuvem (como AWS, Azure e Google Cloud Platform). Ao contrário de soluções tradicionais que podem ser implementadas localmente em clusters físicos, o Databricks elimina a necessidade de gerenciamento de infraestrutura, permitindo que as empresas escalem seus projetos conforme a demanda.

O Apache Spark é o motor subjacente que possibilita o processamento distribuído em larga escala no Databricks. Ele é otimizado para operações de leitura e escrita em massa, bem como para tarefas complexas de análise e aprendizado de máquina. O Spark oferece suporte a tarefas como:

\begin{itemize}
    \item \textbf{Processamento em lote (batch):} Ideal para grandes volumes de dados históricos ou análises periódicas.
    \item \textbf{Processamento em tempo real (streaming):} Permite o consumo e processamento de dados à medida que são gerados, suportando aplicações em tempo real.
    \item \textbf{Análises interativas:} Com Spark SQL e APIs em Python, Scala, R e Java, é possível realizar consultas ad-hoc sobre grandes conjuntos de dados.
\end{itemize}

Além disso, o Databricks permite a execução de notebooks interativos, onde os usuários podem escrever código, visualizar dados e realizar análises em tempo real, tudo dentro da plataforma. Os notebooks são colaborativos, possibilitando a colaboração entre equipes, e podem ser integrados a outras ferramentas de BI (business intelligence) e visualização.

\subsubsection{Modelagem de Dados no Databricks com Delta Tables}

A modelagem de dados no Databricks se apoia diretamente na combinação entre o formato Parquet e a camada transacional do Delta Lake. Essa abordagem não apenas garante governança e consistência, mas também oferece grande flexibilidade para estruturar dados em ambientes distribuídos.

As Delta Tables são construídas sobre arquivos Parquet organizados em diretórios, onde cada arquivo representa um fragmento da tabela. O Parquet utiliza um formato colunar, no qual os valores de cada atributo são armazenados em blocos homogêneos, otimizando compressão, leitura seletiva e paralelismo no processamento. Em essência, cada coluna contém pares estruturados “campo → valores”, o que se aproxima conceitualmente de um document store, no qual cada chave identifica um conjunto de valores associados.

O Delta Lake adiciona uma camada de controle transacional à estrutura colunar. Cada tabela é acompanhada por um transaction log (\_delta\_log), composto por arquivos JSON e Parquet que registram todas as operações aplicadas, incluindo criação, inserção, deleção, atualizações e metadados de esquema. Durante a modelagem, essa combinação fornece:

\begin{itemize}
\item \textbf{Controle ACID sobre arquivos Parquet:} Cada operação é registrada como um conjunto de actions no log, garantindo atomicidade e isolamento mesmo em clusters distribuídos.
\item \textbf{Evolução de esquema:} Alterações de estruturas são aplicadas incrementalmente, preservando compatibilidade com versões anteriores e mantendo rastreabilidade.
\item \textbf{Upserts, merges e deletes eficientes:} O Databricks reescreve apenas os arquivos Parquet impactados, combinando metadados de partições, estatísticas de coluna e índices de arquivos para minimizar I/O.
\item \textbf{Versionamento completo:} Cada modificação gera um novo estado da tabela, permitindo consultas temporais e auditoria detalhada.
\end{itemize}

Na prática, o armazenamento colunar fornece organização clara por atributos, enquanto o Delta Lake oferece mecanismos de governança comparáveis aos de sistemas transacionais clássicos. Essa união permite ao Databricks adotar uma modelagem que preserva estrutura — típica de um banco relacional — e, ao mesmo tempo, mantém características de flexibilidade e granularidade encontradas em modelos orientados a documentos, onde cada coluna funciona como uma chave que referencia seus respectivos valores.

Esse modelo híbrido torna as Delta Tables especialmente adequadas para arquiteturas analíticas, pipelines de larga escala, workloads de machine learning e cenários que exigem leitura seletiva e atualizações complexas em grandes volumes de dados.

\section{Estudo de Caso}

\subsection{Dados Utilizados}

Para a construção do estudo de caso, foram utilizados dois conjuntos de dados públicos referentes a programas de acesso ao ensino superior brasileiro: o \textit{Prouni} e o \textit{Sisu}.  

\textbf{Prouni:} contém registros de inscrições entre os anos de 2006 e 2020, abrangendo atributos como:
\begin{itemize}
    \item \texttt{ano} – ano da inscrição;
    \item \texttt{sigla\_uf} – unidade federativa;
    \item \texttt{id\_municipio} – código do município;
    \item \texttt{cpf} – identificador individual do candidato;
    \item \texttt{sexo}, \texttt{raca\_cor}, \texttt{data\_nascimento} - informações sobre o candidato;
    \item \texttt{beneficiario\_deficiente} – indicador de deficiência;
    \item \texttt{id\_ies}, \texttt{campus}, \texttt{nome\_municipio\_ies} - informações sobre instituição de ensino;
    \item \texttt{curso}, \texttt{turno\_curso}, \texttt{tipo\_bolsa}, \texttt{modalidade\_ensino}.  \newline
\end{itemize}
 

\textbf{Sisu:} contém inscrições entre 2017 e 2022, com foco em cursos das áreas de tecnologia e engenharias, incluindo os seguintes atributos:
\begin{itemize}
    \item \texttt{ano},
    \item \texttt{id\_ies}, \texttt{sigla\_ies} - identificador da instituição de ensino;
    \item \texttt{nome\_curso},  \texttt{modalidade\_concorrencia}  - ; informação sobre inscrição do candidato; 
    \item \texttt{cpf}, \texttt{sexo}, \texttt{data\_nascimento} - informações sobre o candidato;  \newline
\end{itemize}

Ambos os conjuntos de dados possuem tamanho considerável (sisu: 1812156 registros, prouni: 95032 registros) e foram armazenados no Databricks em formato \textit{Delta Lake}, o que permite controle de versionamento e otimização de leitura e escrita.  
O carregamento foi feito utilizando a API do \texttt{PySpark}, com inferência de esquema e gravação em tabelas Delta (\texttt{delta\_sisu} e \texttt{delta\_prouni}).

\subsection{Análises Realizadas}

\textbf{1. Filtragem condicional por sexo (Sisu)}  
A primeira análise buscou identificar o número de inscrições do sexo feminino no Sisu, aplicando um filtro simples sobre o atributo \texttt{sexo}.  
Essa operação visa observar a representatividade feminina em cursos de tecnologia.  


\textbf{2. Busca textual por curso (Sisu)}  
Utilizou-se uma consulta com o operador \texttt{LIKE} para identificar cursos cujo nome contém o termo ``ANÁLISE''.  
Em seguida, os cursos foram agrupados por instituição de ensino (\texttt{sigla\_ies}) e agregados em listas únicas.  


\textbf{3. Média de inscritos por curso em cada instituição (Sisu)}  
Primeiro foi calculada a contagem total de candidatos por curso e instituição, seguida da média de inscritos por curso em cada instituição.  

\textbf{4. Normalização e cruzamento de dados (Sisu e Prouni)}  
Antes da integração, ambos os conjuntos foram sanitizados:
\begin{itemize}
    \item Remoção de acentuação dos nomes de cursos;
    \item Normalização de CPF (remoção de caracteres não numéricos);
    \item Conversão de campos textuais para minúsculas.  \newline
\end{itemize}

Após a normalização, os dados foram gravados novamente como tabelas Delta, garantindo consistência e versionamento.


\textbf{5. Cálculo da média de idade por curso e instituição (Sisu e Prouni)}  
A partir da data de nascimento, foi calculada a idade aproximada dos candidatos em ambos os programas.  
As informações foram unificadas e agrupadas por curso e instituição, permitindo calcular a média de idade e o total de pessoas por grupo.  


\subsection{Síntese do Estudo}

O conjunto de análises permite explorar a estrutura, perfil e inter-relação entre dois programas distintos de ingresso ao ensino superior.  
Ainda que os dados apresentem períodos e escopos diferentes, o uso do Databricks e do formato Delta Lake possibilitou o tratamento, a padronização e o cruzamento eficiente das informações.  



\section{Resultados e Avaliações}

\subsection{Modelagem dos dados}

Para o PostgreSQL, foram geradas as tabelas SQL com campos espelhados aos do Dataset. Seu DDL (Data Definition Language) pode ser conferido nos Anexos.
Quanto a modelagem dentro do databricks, as Delta Tables mapeiam via identificador colunar os conteúdos para dentro dos arquivos .parquet, mantendo também a estrutura dos Datasets CSV.

\subsection{Análises Comparativas}

Os experimentos foram realizados em dois ambientes computacionais com arquiteturas distintas. O primeiro corresponde ao Databricks Serverless Free Edition, um serviço totalmente gerenciado que aloca recursos computacionais de forma elástica, sem permitir ao usuário configurar diretamente a quantidade de CPU, memória ou paralelismo disponível. Nesse modelo, as operações são executadas sobre uma camada distribuída de Spark otimizada para cargas analíticas, com autoscaling transparente e armazenamento nativo em Delta Lake. O segundo ambiente consiste em uma instância PostgreSQL 18 executada em Docker, utilizando integralmente os recursos da máquina hospedeira, já que o contêiner não possui limites explícitos de CPU ou memória definidos.\\  O host local é equipado com um processador Intel Core i5-12500H (12 núcleos híbridos, clock base de 2,5 GHz), 24 GB de memória RAM DDR4 a 3200 MHz (Samsung 8 GB + Kingston 16 GB) e um SSD NVMe Micron 2400 de 512 GB, características que definem o desempenho efetivo disponível para o PostgreSQL durante os testes. O contêiner opera com volumes persistentes, porta 5432 exposta e configuração padrão do PostgreSQL, executando todas as operações de forma relacional e centralizada em um único nó.

\subsection{Dataset SISU}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Operação} & \textbf{PostgreSQL (ms)} & \textbf{Databricks (ms)}\\ \hline
Inserção de Dados & 15707.182 & 6052 \\ \hline
Filtragem condicional & 430.071 & 2068 \\ \hline
Busca de Texto & 993 & 1376 \\ \hline
Busca Média & 128 & 1366 \\ \hline
\end{tabular}
\end{center}

Query de Filtragem adicional (restante das queries no anexo):\\
\begin{verbatim}
SELECT *
FROM sisu
WHERE sexo = 'F';
\end{verbatim}


Os resultados mostram que o Databricks foi mais rápido na inserção de dados, sugerindo maior eficiência no processo de escrita distribuída e no uso do Delta Lake, que aplica compactação de arquivos e paralelização na etapa de carga. Por ser baseado no Spark, o carregamento de arquivos CSV com paralelismo e escrita distríbuida torna o processo duas vezes mais rápido. 

Além disso, no PostgreSQL foi necessário carregar os datasets para dentro do servidor e executar uma query de cópia de dados com delimitadores csv, um processo ineficiente, manual e pouco escalável. No Databricks, seu padrão serverless on-cloud torna o processo mais fácil e rápido que o banco relacional padrão.

No entanto, todas as consultas foram mais rápidas no PostgreSQL, contradizendo a análise anterior. Nas filtragens condicionais, nas buscas textuais e nas consultas de agregação, o Postgres se mostrou superior pelo uso eficiente de indexação e o Databricks apresentou maior latência em consultas devido ao overhead do motor distribuído, que inclui inicialização de jobs, leitura de arquivos particionados e gerenciamento do cluster. Mesmo com paralelização, esse custo fixo reduz o desempenho para operações simples e datasets de pequena ou média escala.

Esse custo fixo se mostra em sua maioria em aproximadamente 1s.

\subsection{Dataset Cruzado ProUni x SISU}

\begin{center}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Operação} & \textbf{PostgreSQL (ms)} & \textbf{Databricks (ms)}\\ \hline
Normalização e cruzamento dos dados & 11435 & 10207 \\ \hline
Busca Média & 1223 & 912 \\ \hline
\end{tabular}
\end{center}

O Databricks apresentou desempenho ligeiramente superior, especialmente nas operações com maior carga de transformação. O processamento distribuído do Spark reduz o tempo total em workloads mais pesados, enquanto o PostgreSQL mantém bom desempenho, mas limitado pela execução em nó único. No conjunto cruzado, as agregações também foram mais rápidas no Databricks, reforçando o benefício do paralelismo em etapas com maior volume intermediário.

\subsubsection*{Análise Comparativa de Memória e I/O no cenário de Busca Média - Prouni x Sisu}

A execução revelou diferenças claras no uso de recursos. O PostgreSQL processou aproximadamente 402 MB em leituras devido ao formato linha-a-linha e ao uso de varreduras completas. Já o Databricks leu apenas 5.55 MB, beneficiando-se do armazenamento colunar, que permite carregar apenas as colunas necessárias. Em contraste, o consumo de memória do Databricks foi maior, pois o mecanismo Photon utiliza vetorização e paralelismo agressivo para reduzir a dependência de operações de disco.

\begin{center}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Métrica} & \textbf{PostgreSQL} & \textbf{Databricks} \\ \hline
Bytes lidos (I/O) & 402 MB & 5.55 MB \\ \hline
Memória utilizada (total) & 3--4 MB & 211 MB \\ \hline
Linhas processadas & 1.9 milhões & 1.9 milhões \\ \hline
Perfil de execução & Armazenamento em linhas & Armazenamento colunar e paralelização \\ \hline
\end{tabular}
\end{center}
Dados e resultados relacionados ao conteúdo da tabela nos Anexos.

A comparação mostra que o PostgreSQL é mais econômico em memória, enquanto o Databricks aumenta o uso de RAM para reduzir leituras de disco e acelerar operações analíticas.

\newline
\section{Conclusão}

A comparação mostra que Databricks e PostgreSQL atendem a propósitos diferentes dentro do processamento de dados. O Databricks, apoiado no Spark e no Delta Lake, teve melhor desempenho em cargas analíticas, transformações intensivas e manipulação de grandes volumes, graças à arquitetura distribuída e ao otimizador Catalyst. Já o PostgreSQL se sobressaiu em consultas relacionais tradicionais, com baixa latência, uso eficiente de índices e forte consistência transacional, o que o torna ideal para aplicações corporativas e cenários OLTP.

Assim, recomenda-se Databricks para pipelines analíticos complexos e processamento massivamente paralelo, enquanto o PostgreSQL permanece mais adequado para estruturas relacionais estáveis e volumes moderados. As tecnologias não competem entre si: combinadas, oferecem uma arquitetura híbrida capaz de explorar o melhor de cada abordagem.
\begin{thebibliography}{99}

\bibitem{databricks}
Introdução ao Databricks no AWS. Disponível em: \url{https://docs.databricks.com/aws/pt/introduction/#casos-de-uso-comuns}
. Acesso em: nov. 2025.

\bibitem{postgresql}
Momjian, B. (2021). \textit{PostgreSQL: Introduction and Concepts}. Addison-Wesley.

\bibitem{sbc}
Sociedade Brasileira de Computação. \textit{Template para Artigos e Capítulos de Livros}. Disponível em: \url{http://www.sbc.org.br/documentos-da-sbc}.

\end{thebibliography}

\section*{Anexos}

Os datasets utilizados neste estudo estão disponíveis publicamente nos links abaixo, bem como o repositório contendo os scripts em Python, códigos SQL e instruções detalhadas de execução.


    \textbf{Dataset SISU (Drive):} \\
    \url{https://drive.google.com/file/d/1gAiybq6FHuZ4XTU8vx-fhlTH5kHuoQrD/view?usp=sharing}
    \\
    \textbf{Dataset ProUni (Drive):} \\
    \url{https://drive.google.com/file/d/1w3Wv72iMsgiDlmy-v3h8ipsBJgiEK7B8/view?usp=sharing}
    \\
    \textbf{Repositório GitHub:} \url{https://github.com/Mateus-X/big_data}

\begin{verbatim}
    -- MODELAGEM DOS DADOS
CREATE TABLE prouni (
    ano SMALLINT NOT NULL,
    sigla_uf CHAR(2) NOT NULL,
    id_municipio INT,
    cpf CHAR(20) NOT NULL,
    sexo CHAR(1) NOT NULL,
    raca_cor SMALLINT,
    data_nascimento DATE,
    beneficiario_deficiente BOOLEAN,
    id_ies INT,
    campus VARCHAR(100),
    nome_municipio_ies VARCHAR(100),
    curso VARCHAR(150),
    turno_curso SMALLINT,
    tipo_bolsa SMALLINT,
    modalidade_ensino SMALLINT
);

CREATE TABLE sisu (
    ano SMALLINT NOT NULL,
    id_ies INT NOT NULL,
    sigla_ies VARCHAR(20),
    nome_curso VARCHAR(150),
    modalidade_concorrencia text,
    cpf CHAR(20) NOT NULL,
    sexo CHAR(1) NOT NULL,
    data_nascimento DATE
);

-- UMA TABELA
-- 
SELECT *
FROM sisu
WHERE sexo = 'F';

SELECT 
    sigla_ies,
    ARRAY_AGG(DISTINCT nome_curso) AS cursos_analise
FROM sisu
WHERE nome_curso ILIKE '%ANÁLISE%'
GROUP BY sigla_ies;

SELECT 
    sigla_ies,
    nome_curso,
    COUNT(*) AS total_pessoas
FROM sisu
GROUP BY sigla_ies, nome_curso;

SELECT 
    sigla_ies,
    AVG(total_pessoas) AS media_pessoas_por_curso
FROM (
    SELECT 
        sigla_ies,
        nome_curso,
        COUNT(*) AS total_pessoas
    FROM sisu
    GROUP BY sigla_ies, nome_curso
) AS qtd_por_curso_instituicao
GROUP BY sigla_ies
ORDER BY media_pessoas_por_curso DESC;


-- DUAS TABELAS 
-- Normaliza as tabelas e grava em tabelas auxiliares
CREATE TABLE prouni_norm AS
SELECT
    *,
    lower(unaccent(curso)) AS curso_norm,
    regexp_replace(cpf, '\D', '', 'g') AS cpf_norm
FROM prouni;

CREATE TABLE sisu_norm AS
SELECT
    *,
    lower(unaccent(nome_curso)) AS curso_norm,
    regexp_replace(cpf, '\D', '', 'g') AS cpf_norm
FROM sisu;

-- Prouni
CREATE TEMP TABLE prouni_ano AS
SELECT
    cpf_norm AS cpf,
    MAX(ano) AS ano_prouni
FROM prouni_norm
WHERE curso_norm LIKE '%analise e desenvolvimento de sistemas%'
GROUP BY cpf_norm;

-- Sisu
CREATE TEMP TABLE sisu_ano AS
SELECT
    cpf_norm AS cpf,
    MAX(ano) AS ano_sisu
FROM sisu_norm
WHERE curso_norm LIKE '%analise e desenvolvimento de sistemas%'
GROUP BY cpf_norm;

SELECT
    p.cpf,
    p.ano_prouni,
    s.ano_sisu
FROM prouni_ano p
JOIN sisu_ano s ON p.cpf = s.cpf
WHERE s.ano_sisu > p.ano_prouni
ORDER BY p.cpf;

-- União das duas tabelas com cálculo de idade
WITH prouni_idade AS (
    SELECT
        id_ies,
        lower(unaccent(curso)) AS curso,
        FLOOR(EXTRACT(YEAR FROM AGE(current_date, data_nascimento))) AS idade
    FROM prouni
),
sisu_idade AS (
    SELECT
        id_ies,
        lower(unaccent(nome_curso)) AS curso,
        FLOOR(EXTRACT(YEAR FROM AGE(current_date, data_nascimento))) AS idade
    FROM sisu
),
todas AS (
    SELECT * FROM prouni_idade
    UNION ALL
    SELECT * FROM sisu_idade
)
SELECT
    curso,
    id_ies,
    COUNT(idade) AS total_pessoas,
    ROUND(AVG(idade)::numeric, 2) AS media_idade
FROM todas
GROUP BY curso, id_ies
ORDER BY media_idade DESC;





-- Análise de memória
WITH prouni_idade AS (
    SELECT
        id_ies,
        lower(unaccent(curso)) AS curso,
        FLOOR(EXTRACT(YEAR FROM AGE(current_date, data_nascimento))) AS idade
    FROM prouni
),
sisu_idade AS (
    SELECT
        id_ies,
        lower(unaccent(nome_curso)) AS curso,
        FLOOR(EXTRACT(YEAR FROM AGE(current_date, data_nascimento))) AS idade
    FROM sisu
),
todas AS (
    SELECT * FROM prouni_idade
    UNION ALL
    SELECT * FROM sisu_idade
)
SELECT
    curso,
    id_ies,
    COUNT(idade) AS total_pessoas,
    ROUND(AVG(idade)::numeric, 2) AS media_idade
FROM todas
GROUP BY curso, id_ies
ORDER BY media_idade DESC;

-- Resultado
web_II=# EXPLAIN (ANALYZE, BUFFERS) WITH prouni_idade AS (
    SELECT
        id_ies,
        lower(unaccent(curso)) AS curso,
        FLOOR(EXTRACT(YEAR FROM AGE(current_date, data_nascimento))) AS idade
    FROM prouni
),
sisu_idade AS (
    SELECT
        id_ies,
        lower(unaccent(nome_curso)) AS curso,
        FLOOR(EXTRACT(YEAR FROM AGE(current_date, data_nascimento))) AS idade
    FROM sisu
),
todas AS (
    SELECT * FROM prouni_idade
    UNION ALL
    SELECT * FROM sisu_idade
)
SELECT
    curso,
    id_ies,
    COUNT(idade) AS total_pessoas,
    ROUND(AVG(idade)::numeric, 2) AS media_idade
FROM todas
GROUP BY curso, id_ies
ORDER BY media_idade DESC;                                                                           QUERY PLAN                                                           
                
------------------------------------------------------------------------------------------------------------------------------------------------
----------------
 Sort  (cost=217142.93..217242.93 rows=40000 width=76) (actual time=1616.789..1621.735 rows=1818.00 loops=1)
   Sort Key: (round(avg((floor(EXTRACT(year FROM age((CURRENT_DATE)::timestamp with time zone, (sisu.data_nascimento)::timestamp with time zone)
)))), 2)) DESC
   Sort Method: quicksort  Memory: 183kB
   Buffers: shared hit=7072 read=44332
   ->  Finalize GroupAggregate  (cost=201104.60..214085.38 rows=40000 width=76) (actual time=1611.783..1620.218 rows=1818.00 loops=1)
         Group Key: (lower(unaccent((sisu.nome_curso)::text))), sisu.id_ies
         Buffers: shared hit=7072 read=44332
         ->  Gather Merge  (cost=201104.60..212285.38 rows=96000 width=76) (actual time=1611.656..1617.726 rows=3117.00 loops=1)
               Workers Planned: 2
               Workers Launched: 2
               Buffers: shared hit=7072 read=44332
               ->  Sort  (cost=200104.58..200204.58 rows=40000 width=76) (actual time=1455.657..1455.816 rows=1039.00 loops=3)
                     Sort Key: (lower(unaccent((sisu.nome_curso)::text))), sisu.id_ies
                     Sort Method: quicksort  Memory: 281kB
                     Buffers: shared hit=7072 read=44332
                     Worker 0:  Sort Method: quicksort  Memory: 152kB
                     Worker 1:  Sort Method: quicksort  Memory: 66kB
                           ->  Partial HashAggregate  (cost=177917.97..197047.04 rows=40000 width=76) (actual time=1452.369..1453.346 rows=1039.00 loops=3)
                           Group Key: (lower(unaccent((sisu.nome_curso)::text))), sisu.id_ies
                           Planned Partitions: 4  Batches: 1  Memory Usage: 1553kB
                           Buffers: shared hit=7042 read=44332
                           Worker 0:  Batches: 1  Memory Usage: 1169kB
                           Worker 1:  Batches: 1  Memory Usage: 689kB
                           ->  Parallel Append  (cost=0.00..79556.52 rows=794840 width=68) (actual time=37.783..1261.406 rows=635729.33 loops=3)
                                 Buffers: shared hit=7042 read=44332
                                 ->  Parallel Seq Scan on sisu  (cost=0.00..72337.29 rows=755243 width=68) (actual time=8.964..1097.532 rows=604
052.00 loops=3)
                                       Buffers: shared hit=5411 read=44332
                                 ->  Parallel Seq Scan on prouni  (cost=0.00..3245.04 rows=55901 width=68) (actual time=45.092..160.193 rows=475
16.00 loops=2)
                                       Buffers: shared hit=1631
 Planning Time: 8.918 ms
 JIT:
   Functions: 36
   Options: Inlining false, Optimization false, Expressions true, Deforming true
   Timing: Generation 19.078 ms (Deform 5.966 ms), Inlining 0.000 ms, Optimization 10.944 ms, Emission 94.256 ms, Total 124.278 ms
 Execution Time: 1636.690 ms
(35 rows)

(END)


\end{verbatim}

\end{document}